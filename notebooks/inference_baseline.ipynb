{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "national-luxembourg",
   "metadata": {},
   "source": [
    "<pre>\n",
    "baseline model 을 실행해 보겠습니다.\n",
    "\n",
    "baseline model은 jupyter 상에서 제공되지는 않습니다.\n",
    "다만, 세팅된 docker 환경은 baseline model을 실행하기에 충분한 환경입니다.\n",
    "\n",
    "당 competetion의 공식 baseline model은 <a href=\"https://github.com/KbeautyHair/KbeautyBaseline\">https://github.com/KbeautyHair/KbeautyBaseline</a>입니다. baseline model의 공식 저작자와 기술에 대한 정보를 얻고 싶다면 앞의 github link를 참조하세요\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "conditional-formation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'KbeautyBaseline'...\n",
      "remote: Enumerating objects: 9, done.\u001b[K\n",
      "remote: Counting objects: 100% (9/9), done.\u001b[K\n",
      "remote: Compressing objects: 100% (9/9), done.\u001b[K\n",
      "remote: Total 157 (delta 4), reused 0 (delta 0), pack-reused 148\u001b[K\n",
      "Receiving objects: 100% (157/157), 4.44 MiB | 3.23 MiB/s, done.\n",
      "Resolving deltas: 100% (66/66), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/KbeautyHair/KbeautyBaseline.git"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eleven-lincoln",
   "metadata": {},
   "source": [
    "<pre>\n",
    "baseline의 공식 설명에 따르면, pretrained 파일을 불러오기 위해서는 가중치파일을 다운받아야 합니다.\n",
    "공식 모델 github에도 존재하지만, 대회를 위해 바로 다운로드 가능한 endpoint에서 한시적으로 serving 할 예정입니다.\n",
    "\n",
    "용량이 상당하므로 본인의 컴퓨터가 네트워크가 느리다면 차라도 한잔 하고 오는 것을 추천합니다.\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dedicated-constitution",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-01-31 14:40:06--  https://robot-public.s3.ap-northeast-2.amazonaws.com/baseline/060000_nets_ema.ckpt\n",
      "Resolving robot-public.s3.ap-northeast-2.amazonaws.com (robot-public.s3.ap-northeast-2.amazonaws.com)... 52.219.60.39\n",
      "Connecting to robot-public.s3.ap-northeast-2.amazonaws.com (robot-public.s3.ap-northeast-2.amazonaws.com)|52.219.60.39|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 229463581 (219M) [application/x-www-form-urlencoded]\n",
      "Saving to: ‘060000_nets_ema.ckpt’\n",
      "\n",
      "060000_nets_ema.ckp 100%[===================>] 218.83M  97.6MB/s    in 2.2s    \n",
      "\n",
      "2021-01-31 14:40:09 (97.6 MB/s) - ‘060000_nets_ema.ckpt’ saved [229463581/229463581]\n",
      "\n",
      "--2021-01-31 14:40:09--  https://robot-public.s3.ap-northeast-2.amazonaws.com/baseline/060000_nets.ckpt\n",
      "Resolving robot-public.s3.ap-northeast-2.amazonaws.com (robot-public.s3.ap-northeast-2.amazonaws.com)... 52.219.60.39\n",
      "Connecting to robot-public.s3.ap-northeast-2.amazonaws.com (robot-public.s3.ap-northeast-2.amazonaws.com)|52.219.60.39|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 313002483 (299M) [application/x-www-form-urlencoded]\n",
      "Saving to: ‘060000_nets.ckpt’\n",
      "\n",
      "060000_nets.ckpt    100%[===================>] 298.50M  96.0MB/s    in 3.1s    \n",
      "\n",
      "2021-01-31 14:40:12 (96.0 MB/s) - ‘060000_nets.ckpt’ saved [313002483/313002483]\n",
      "\n",
      "--2021-01-31 14:40:13--  https://robot-public.s3.ap-northeast-2.amazonaws.com/baseline/060000_nets_optims.ckpt\n",
      "Resolving robot-public.s3.ap-northeast-2.amazonaws.com (robot-public.s3.ap-northeast-2.amazonaws.com)... 52.219.148.27\n",
      "Connecting to robot-public.s3.ap-northeast-2.amazonaws.com (robot-public.s3.ap-northeast-2.amazonaws.com)|52.219.148.27|:443... connected.\n",
      "HTTP request sent, awaiting response... 403 Forbidden\n",
      "2021-01-31 14:40:13 ERROR 403: Forbidden.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "!cd /main/notebooks/KbeautyBaseline/expr/checkpoints/k-hairstyle/ && wget https://robot-public.s3.ap-northeast-2.amazonaws.com/baseline/060000_nets_ema.ckpt\n",
    "!cd /main/notebooks/KbeautyBaseline/expr/checkpoints/k-hairstyle/ && wget https://robot-public.s3.ap-northeast-2.amazonaws.com/baseline/060000_nets.ckpt\n",
    "!cd /main/notebooks/KbeautyBaseline/expr/checkpoints/k-hairstyle/ && wget https://robot-public.s3.ap-northeast-2.amazonaws.com/baseline/060000_nets_optims.ckpt    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "specified-mills",
   "metadata": {},
   "source": [
    "설치된 파이토치의 버젼과 gpu 가능 여부,  그리고 nvidia-smi설정을 열어봅시다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "coordinate-apparatus",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device : Tesla T4\n",
      "torch version : 1.4.0+cu100\n",
      "Sun Jan 31 14:50:18 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla T4            On   | 00000000:00:1E.0 Off |                    0 |\n",
      "| N/A   28C    P8     9W /  70W |      3MiB / 15109MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "if torch.cuda.is_available():\n",
    "    print(\"device :\",torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    print(\"device : cpu only\")\n",
    "\n",
    "print(\"torch version :\",torch.__version__)\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "verified-honor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(batch_size=8, beta1=0.0, beta2=0.99, checkpoint_dir='expr/checkpoints/k-hairstyle', dataset_dir='imagelists', ds_iter=100000, eval_dir='expr/eval/k-hairstyle', eval_every=30000, f_lr=1e-06, hidden_dim=512, img_size=512, lambda_cyc=2, lambda_ds=1, lambda_reg=1, lambda_sty=2, latent_dim=16, lm_path='expr/checkpoints/celeba_lm_mean.npz', lr=0.0001, mode='sample', num_domains=2, num_sample=300, num_workers=8, print_every=10, randcrop_prob=0.5, ref_dir='sample_images/ref', result_dir='expr/results/k-hairstyle', resume_iter=60000, sample_dir='expr/samples/k-hairstyle', sample_every=5000, save_every=10000, seed=777, src_dir='sample_images/src', src_domain=0, style_dim=64, test_img_dir='data/mqset', total_iters=100000, train_img_dir='data/mqset', trg_domain=0, val_batch_size=32, val_img_dir='data/mqset', w_hpf=0.0, weight_decay=0.0001, wing_path='expr/checkpoints/wing.ckpt')\n",
      "Number of parameters of generator: 33964099\n",
      "Number of parameters of mapping_network: 2438272\n",
      "Number of parameters of style_encoder: 20945824\n",
      "Number of parameters of discriminator: 20881186\n",
      "Initializing generator...\n",
      "Initializing mapping_network...\n",
      "Initializing style_encoder...\n",
      "Initializing discriminator...\n",
      "Loading checkpoint from expr/checkpoints/k-hairstyle/060000_nets_ema.ckpt...\n",
      "Traceback (most recent call last):\n",
      "  File \"main.py\", line 177, in <module>\n",
      "    main(args)\n",
      "  File \"main.py\", line 64, in main\n",
      "    solver.sample()\n",
      "  File \"/main/notebooks/KbeautyBaseline/core/solver.py\", line 189, in sample\n",
      "    self._load_checkpoint(args.resume_iter)\n",
      "  File \"/main/notebooks/KbeautyBaseline/core/solver.py\", line 85, in _load_checkpoint\n",
      "    ckptio.load(step)\n",
      "  File \"/main/notebooks/KbeautyBaseline/core/checkpoint.py\", line 37, in load\n",
      "    module_dict = torch.load(fname)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/torch/serialization.py\", line 527, in load\n",
      "    with _open_zipfile_reader(f) as opened_zipfile:\n",
      "  File \"/usr/local/lib/python3.6/site-packages/torch/serialization.py\", line 224, in __init__\n",
      "    super(_open_zipfile_reader, self).__init__(torch._C.PyTorchFileReader(name_or_buffer))\n",
      "RuntimeError: version_ <= kMaxSupportedFileFormatVersion INTERNAL ASSERT FAILED at /pytorch/caffe2/serialize/inline_container.cc:132, please report a bug to PyTorch. Attempted to read a PyTorch file with version 3, but the maximum supported version for reading is 2. Your PyTorch installation may be too old. (init at /pytorch/caffe2/serialize/inline_container.cc:132)\n",
      "frame #0: c10::Error::Error(c10::SourceLocation, std::string const&) + 0x33 (0x7f2177ebe193 in /usr/local/lib/python3.6/site-packages/torch/lib/libc10.so)\n",
      "frame #1: caffe2::serialize::PyTorchStreamReader::init() + 0x1f5b (0x7f2042a9eafb in /usr/local/lib/python3.6/site-packages/torch/lib/libtorch.so)\n",
      "frame #2: caffe2::serialize::PyTorchStreamReader::PyTorchStreamReader(std::string const&) + 0x64 (0x7f2042a9fd14 in /usr/local/lib/python3.6/site-packages/torch/lib/libtorch.so)\n",
      "frame #3: <unknown function> + 0x6c5106 (0x7f219131c106 in /usr/local/lib/python3.6/site-packages/torch/lib/libtorch_python.so)\n",
      "frame #4: <unknown function> + 0x295f24 (0x7f2190eecf24 in /usr/local/lib/python3.6/site-packages/torch/lib/libtorch_python.so)\n",
      "<omitting python frames>\n",
      "frame #43: __libc_start_main + 0xe7 (0x7f2197f45bf7 in /lib/x86_64-linux-gnu/libc.so.6)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!cd /main/notebooks/KbeautyBaseline && python3 main.py --mode sample --img_size 512 --num_domains 2 --resume_iter 60000 --w_hpf 0 --checkpoint_dir expr/checkpoints/k-hairstyle --result_dir expr/results/k-hairstyle --trg_domain 0 --src_dir sample_images/src --ref_dir sample_images/ref               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "polished-preference",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "obvious-cement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Jan 31 14:46:19 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla T4            On   | 00000000:00:1E.0 Off |                    0 |\n",
      "| N/A   28C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "compact-ordinary",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.4.0+cu100'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "divided-polls",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
